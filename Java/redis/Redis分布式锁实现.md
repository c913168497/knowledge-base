
#### redis 加锁命令
```
SETNX resource_name my_random_value PX 30000

这个命令只有在 key 不存在的时候才会设置 key 的值 (SETNX)， 超时时间设为 30000 毫秒(PX)
这个key的值设为 "my_random_value" 。这个值必须在所有获取锁请求的客户端里保唯一。
```
##### 命令解释
SETNX 值保持唯一的是为了确保安全的释放锁，避免误删其它客户端得到的锁，这句话什么意思呢

举个例子 
一个客户端拿到了锁，被某个长时间的操作阻塞，从而锁超时后自动释放了锁，但是这个等长时间操作结束之后 客户端又尝试删除这个其实已经被其它客户端拿到的锁。 所以单纯的用DEL指令就有可能造成一个客户端删除了其它客户端的锁，通过校验这个值保证每个客户端都用一个随机字符串'签名'了，这样每个锁只能被获得锁的客户端删除了

#### 具体实现
我们采用 redis lua 脚本实现

```
if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end
```

#### 问题一 加锁的业务逻辑执行超出锁超时限制，导致两个客户端同时持有锁

具体描述
如果在加锁和释放之间的逻辑执行时间太长 以至于超出了锁设定的超时限制，那么就会出现问题。
第一个线程/请求 的逻辑还在处理，但是锁由于超时导致锁已经失效，这时候第二个线程提前重新拥有了这把锁，那么请求的上一个线程/请求的逻辑则不能得到严格的串行执行。

###### 常见方案
- 调大锁的超时时间，之后如果再因为超时带来并发问题，那么人工介入修正数据
- 执行业务逻辑是发现锁快要超时时，只要这个锁的 key 还存在还等于客户端设置的那个值，客户端给 redis 服务实例发送一个 lua 脚本 让 redis 延长锁的时间。 不过这也会带来一个问题，如果一直阻塞那么就自动超时失效的意义就不存在了，这里需要注意，可以考虑加个次数判断，或者超时最大总时间判断 


#### 问题二 redis 集群中 单点故障 主从切换带来的两个客户端同时持有锁
描述：
在生产环境中，我们一般都是主从模式，主节点挂掉时，从节点取而代之，客户端上不会有明显感知。
原先第一个客户端在主节点申请成功了一把锁，但是当锁的数据还没有同步到从节点时，主节点挂掉了，这时候从节点变成了主节点，这个新的节点没有这把锁，这时候客户端请求过来时，实际上上一个请求的业务处理还在执行中，但是到新节点直接获取了新的锁，此时执行就不会是串行执行，数据就会出现不安全问题 当然这种不安全仅仅出现在主从发送 failover 情况下产生，持续时间极短

#####  常见方案
RedLock 算法
这个算法流程较为复杂，不过已经有很多开源的library 做了良好的封装 如 redlock-py

lua 脚本
```
import redlock
  addrs = [{
      "host": "localhost",
      "port": 6379,
      "db": 0
     }, {
      "host": "localhost",
      "port": 6479, 
      "db": 0 
      }, { 
       "host": "localhost",
       "port": 6579,
       "db": 0 
  }]
 dlm = redlock.Redlock(addrs)
 success = dlm.lock("user-lck-laoqian", 5000)
 if success:
     print 'lock success' 
     dlm.unlock('user-lck-laoqian') 
else:
     print 'lock failed'
```

这里推荐一下一个通用的工具

https://github.com/kekingcn/spring-boot-klock-starter
